import cv2
import numpy as np
from PIL import Image


svm = cv2.ml.SVM_load('svm_data.dat')


def get_img_feature(img):
    # svm 中针对固定字体的图像, 直接 resize 图像作为特征比 hog 效果更好
    return cv2.resize(img, (16, 16)).reshape((256, 1))


def predict(gray_img):
    res = svm.predict(np.float32([get_img_feature(gray_img)]))
    return chr(res[1])


def crop_char_img(img):
    h, w = img.shape[:2]
    has_black = False
    last_x = None
    res = []
    for x in range(0, w):
        for y in range(0, h):
            has_black = False
            if img[y][x] < 127:
                has_black = True
                if not last_x:
                    last_x = x
                break
        if not has_black and last_x:
            if x - last_x > 5:
                min_y = None
                max_y = None
                for y1 in range(0, h):
                    has_black = False
                    for x1 in range(last_x, x):
                        if img[y1][x1] < 127:
                            has_black = True
                            if min_y is None:
                                min_y = y1
                            break
                    if not has_black and min_y is not None and max_y is None:
                        max_y = y1
                        break
                res.append(img[min_y:max_y, last_x:x])
            last_x = None
    return res


def thresholding(image):
    img = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]
    if img[0, 0] < 127:
        img = ~img
    return img


def pil_to_cv_gray_img(pil_img):
    arr = np.asarray(pil_img, dtype=np.uint8)
    return cv2.cvtColor(arr, cv2.COLOR_RGB2GRAY)


def invert_cv_gray_img_color(img):
    return ~img


def cut_tag(screen, w, pt):
    img_h, img_w = screen.shape[:2]
    tag_w = 130
    tag = thresholding(screen[pt[1] - 1:pt[1] + 40, pt[0] + w + 3:pt[0] + tag_w + w])
    # 130 像素不一定能将 tag 截全，所以再检查一次看是否需要拓宽 tag 长度
    for i in range(3):
        for j in range(40):
            if tag[j][tag_w - 4 - i] < 127:
                tag_w = 160
                if pt[0] + w + tag_w >= img_w:
                    return None
                tag = thresholding(screen[pt[1] - 1:pt[1] + 40, pt[0] + w + 3:pt[0] + tag_w + w])
                break
    return tag


def remove_holes(img):
    # 去除小连通域
    # findContours 只能处理黑底白字的图像, 所以需要进行一下翻转
    contours, hierarchy = cv2.findContours(~img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    for i in range(len(contours)):
        # 计算区块面积
        area = cv2.contourArea(contours[i])
        if area < 8:
            # 将面积较小的点涂成白色，以去除噪点
            cv2.drawContours(img, [contours[i]], 0, 255, -1)


def recognize_stage_tags(pil_screen, template):
    screen = pil_to_cv_gray_img(pil_screen)
    img_h, img_w = screen.shape[:2]
    if img_h != 1080:
        ratio = 1080 / img_h
        screen = cv2.resize(screen, (int(img_w * ratio), 1080))
    # cv2.imshow('test', screen)
    # cv2.waitKey()
    template = pil_to_cv_gray_img(template.copy())
    result = cv2.matchTemplate(screen, template, cv2.TM_CCOEFF_NORMED)
    threshold = 0.8
    loc = np.where(result >= threshold)
    h, w = template.shape[:2]
    img_h, img_w = screen.shape[:2]
    tag_set = set()
    res = []
    for pt in zip(*loc[::-1]):
        pos_key = '%d-%d' % (pt[0] / 100, pt[1] / 100)
        if pos_key in tag_set:
            continue
        tag_set.add(pos_key)
        # cv2.rectangle(screen, pt, (pt[0] + w, pt[1] + h), (7, 249, 151), 3)
        tag_w = 130
        # 检查边缘像素是否超出截图的范围
        if pt[0] + w + tag_w < img_w:
            tag = cut_tag(screen, w, pt)
            if tag is None:
                continue
            remove_holes(tag)
            tag_str = do_tag_ocr(tag)
            res.append({'tag_img': tag, 'pos': (pt[0] + (tag_w / 2), pt[1] + 20), 'tag_str': tag_str})
    return res


def get_all_tag_images(cv_gray_img, cv_template):
    screen = cv_gray_img
    img_h, img_w = screen.shape[:2]
    if img_h != 1080:
        ratio = 1080 / img_h
        screen = cv2.resize(screen, (int(img_w * ratio), 1080))
    # cv2.imshow('test', screen)
    # cv2.waitKey()
    template = cv_template
    result = cv2.matchTemplate(screen, template, cv2.TM_CCOEFF_NORMED)
    threshold = 0.8
    loc = np.where(result >= threshold)
    h, w = template.shape[:2]
    img_h, img_w = screen.shape[:2]
    tag_set = set()
    res = []
    for pt in zip(*loc[::-1]):
        pos_key = '%d-%d' % (pt[0] / 100, pt[1] / 100)
        if pos_key in tag_set:
            continue
        tag_set.add(pos_key)
        # cv2.rectangle(screen, pt, (pt[0] + w, pt[1] + h), (7, 249, 151), 3)
        tag_w = 130
        # 检查边缘像素是否超出截图的范围
        if pt[0] + w + tag_w < img_w:
            tag = cut_tag(screen, w, pt)
            if tag is None:
                continue
            remove_holes(tag)
            res.append({'tag_img': tag, 'pos': (pt[0] + (tag_w / 2), pt[1] + 20)})
    return res


def do_tag_ocr(img):
    char_imgs = crop_char_img(img)
    s = ''
    for char_img in char_imgs:
        c = predict(char_img)
        s += c
    return s


if __name__ == '__main__':
    gray_screen = Image.open('images/screen.png')
    stage_icon1 = Image.open('images/stage_icon1.png')
    stage_icon2 = Image.open('images/stage_icon2.png')
    tag_infos = []
    tag_infos += recognize_stage_tags(gray_screen, stage_icon1)
    tag_infos += recognize_stage_tags(gray_screen, stage_icon2)
    print(tag_infos)
